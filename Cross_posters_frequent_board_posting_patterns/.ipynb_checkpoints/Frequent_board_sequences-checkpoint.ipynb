{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy: identify any frequent sequential patterns in where authors posted (where ppl post first, then next, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import findspark\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "import pyspark\n",
    "from pyspark.sql import  Row, SparkSession\n",
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.sql.functions import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source files\n",
    "raw_forum_posts = \"FullForumHistory.csv\"\n",
    "board_sequences = \"BoardSequenceResults.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv(raw_forum_posts)\n",
    "print(\"We have {} individual posts by {} unique users\".format(data.shape[0],len(data.user_name.value_counts())))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date = pd.to_datetime(data.date)\n",
    "data.sort_values(by=['date'], inplace=True)\n",
    "print(\"Our posts span {} until {}\".format(str(data.date.iloc[0]),str(data.date.iloc[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_boardname(boardname):\n",
    "    board_words = boardname.split(' ')\n",
    "    if len(board_words) == 0:\n",
    "        return 'got_zero_len_boardname'\n",
    "    elif len(board_words) == 1:\n",
    "        return board_words[0] + '_' + '_'\n",
    "    elif len(board_words) == 2:\n",
    "        return '_'.join([board_words[0],board_words[1]]) + '_'\n",
    "    else:\n",
    "        return '_'.join([board_words[0],board_words[1],board_words[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['board_short'] = data.apply(lambda x: truncate_boardname(x.board_name),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down dataset and groupby user\n",
    "board_postings = data.filter(['user_name','board_short','date'])\n",
    "board_post_seqs_by_user = data.groupby('user_name').agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_post_seqs_by_user['cumu_posts'] = board_post_seqs_by_user.apply(lambda x: len(x.board_name),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01      1.0\n",
       "0.25      1.0\n",
       "0.50      3.0\n",
       "0.80     11.0\n",
       "0.90     30.0\n",
       "0.99    349.0\n",
       "Name: cumu_posts, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the quantiles of users?\n",
    "board_post_seqs_by_user.cumu_posts.quantile([.01,.25,.5,.8,.9,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 9%, we filter to ONLY those with 30 <= cumu_posts < 350\n",
    "board_post_seqs_by_user = board_post_seqs_by_user[(board_post_seqs_by_user.cumu_posts >= 30) & (board_post_seqs_by_user.cumu_posts < 350)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_post_seqs_by_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot check we're in date order \n",
    "audit = random.choice(range(0,board_post_seqs_by_user.shape[0]))\n",
    "auditee = board_post_seqs_by_user.index[audit]\n",
    "for pair in zip(board_post_seqs_by_user.date[audit],board_post_seqs_by_user.board_short[audit]):\n",
    "    print(auditee,pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Investigating head-of-thread posts versus replies\n",
    "# def prepend_type_truncate_boardname(boardname,post_type):\n",
    "#     if post_type == 'thread':\n",
    "#         prepend = 'Th____'\n",
    "#     else:\n",
    "#         prepend = 'R____'\n",
    "#     board_words = boardname.split(' ')\n",
    "#     if len(board_words) == 0:\n",
    "#         return 'got_zero_len_boardname'\n",
    "#     elif len(board_words) == 1:\n",
    "#         return prepend + '*' + board_words[0] + '_' + '_'\n",
    "#     elif len(board_words) == 2:\n",
    "#         return prepend + '*' + '_'.join([board_words[0],board_words[1]]) + '_'\n",
    "#     else:\n",
    "#         return prepend + '*' + '_'.join([board_words[0],board_words[1],board_words[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['type_board_short'] = data.apply(lambda x: prepend_type_truncate_boardname(x.board_name,x.doc_type),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter down dataset and groupby user\n",
    "# board_postings = data.filter(['user_name','type_board_short','date'])\n",
    "# board_post_seqs_by_user = data.groupby('user_name').agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spot check we're in date order \n",
    "# audit = random.choice(range(0,board_post_seqs_by_user.shape[0]))\n",
    "# auditee = board_post_seqs_by_user.index[audit]\n",
    "# for pair in zip(board_post_seqs_by_user.date[audit],board_post_seqs_by_user.type_board_short[audit]):\n",
    "#     print(auditee,pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does above match raw file lookup, in order?\n",
    "data.loc[data.user_name == auditee] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Peel off board sequences and write them out \n",
    "# board_seqs = np.array(board_post_seqs_by_user.type_board_short)\n",
    "# with open(\"board_sequencesAndTypes.txt\",\"w\") as f:\n",
    "#     f.write(\"\\n\".join(\" \".join(map(str, x)) for x in board_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peel off board sequences and write them out \n",
    "board_seqs = np.array(board_post_seqs_by_user.board_short)\n",
    "with open(\"the9_board_sequences.txt\",\"w\") as f:\n",
    "    f.write(\"\\n\".join(\" \".join(map(str, x)) for x in board_seqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin mining for frequent sequential patterns in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now start Spark\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"board_sequencer\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(board_sequences) as f:  \n",
    "    for cnt, line in enumerate(f):\n",
    "        lines.append(line.strip())\n",
    "        \n",
    "seqs = {}\n",
    "for i in range(len(lines)):\n",
    "    seqs[i] = [[board] for board in lines[i].split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in seqs.keys():\n",
    "    seqs[j] = Row(sequence=seqs[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "makey_framey = tuple()\n",
    "for key in seqs.keys():\n",
    "    new=(seqs[key],)\n",
    "    makey_framey = makey_framey + new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.parallelize(makey_framey).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to analyze 1062 users' board-posting sequences\n"
     ]
    }
   ],
   "source": [
    "user_count = df.count()\n",
    "print(\"Ready to analyze {} users' board-posting sequences\".format(user_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PrefixSpan to look for freqent sequential patterns (which are like author itineraries in their forum journey)\n",
    "minSupport = 0.05 # Pattern must occur in this proportion of user sequences, or gets ignored\n",
    "# In other words, a sequential pattern appearing more than minSupport * numUsers will be output \n",
    "maxPatternLength = 6 # The maximal length of sequential pattern we are seeking\n",
    "prefixSpan = PrefixSpan(minSupport=minSupport, maxPatternLength=maxPatternLength)\n",
    "output = prefixSpan.findFrequentSequentialPatterns(df).sort(\"freq\",ascending=False).cache() # this is the action step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = output.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['pattern_length'] = pdf.apply(lambda x: len(x.sequence) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,pdf.pattern_length.max()+1):\n",
    "    pdf[pdf.pattern_length == i][['sequence','freq']]\\\n",
    "    .to_csv(\"Sequential_patterns_of_length_{}.csv\".format(i), sep=\",\",columns = ['sequence','freq'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
